{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMal8ld2tlL33E0rsvgROL5"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Dive to Normalizing Flows\n",
        "---"
      ],
      "metadata": {
        "id": "l9vDGpenj4p1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Вывод нормализующих потоков\n",
        "\n",
        "Давайте посмотрим еще раз на этот рисунок и попробуем расписать итерационный процесс\n",
        "\n",
        "<figure>\n",
        "<img src=\"https://lilianweng.github.io/posts/2018-10-13-flow-models/normalizing-flow.png\" alt=\"Примеры схем генеративных моделй\" style=\"width:100%\">\n",
        "<figcaption align = \"center\">Иллюстрация преобразования нормально распределенного z0 в zK из реального  распределения.</figcaption>\n",
        "</figure>\n",
        "\n",
        "Положим, существуют\n",
        "$$\n",
        "z_{i-1}\\sim p_{i-1}(z_{i-1}), ~ z_i = f_i(z_{i-1})\\Leftrightarrow z_{i-1} = f^{-1}_i(z_i)\n",
        "$$\n",
        "\n",
        "где $z_{i-1}$ — вектор, распределенный как $p_{i-1}$, а $f_i$ — функция, отображающая $z_{i-1}$ в $z_i$. Также существует обратная к $f$ функция $f^{-1}$, которая отображает в обратную сторону.\n",
        "\n",
        "Переход потграфу на рисунке можно расписать\n",
        "\n",
        "$$\n",
        "\\begin{split}\n",
        "p_i(z_i) & \\stackrel{(1)}{=} p_{i-1}(f_i^{-1}(z_i))\\left|\\det\\left(\\dfrac{df^{-1}_i(z_i)}{dz_i}\\right)\\right| \\\\\n",
        "& \\stackrel{(2)}{=} p_{i-1}(z_{i-1})\\left|\\det\\left(\\dfrac{df_i(z_{i-1})}{dz_{i-1}}\\right)^{-1}\\right| \\\\\n",
        "& \\stackrel{(3)}{=} p_{i-1}(z_{i-1})\\left|\\det\\left(\\dfrac{df_i(z_{i-1})}{dz_{i-1}}\\right)\\right|^{-1} \\\\\n",
        "\\end{split}\n",
        "$$\n",
        "\n",
        "Разберем подробнее каждый переход\n",
        "\n",
        "1. Получено из теоремы о замене переменной для многомерных случайных величин.\n",
        "2. Следует из теоремы об обратимых функциях.\n",
        "3. Для обратимых матриц существует свойство определителя $\\det(A^{-1}) = \\det(A)^{-1}$."
      ],
      "metadata": {
        "id": "rkFlAPKoj9Ku"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Теорема о замене переменной\n",
        "\n",
        "Положим существует переменная $z$ распределенная как $z\\sim\\pi(z)$, при помощи которой мы хотим получить новую независимую переменную, используя преобразование $x=f(z)$. Функцию $f$ выберем так, что $\\exists f^{-1}: z=f^{-1}(x)$. Вопрос, каким будет распределение $x\\sim p(x)$?\n",
        "$$\n",
        "\\int p(x)dx=\\int\\pi(z)dz = 1\n",
        "$$\n",
        "\n",
        "$$\n",
        "p(x) = \\pi(z)\\left|\\dfrac{dz}{dx}\\right| = \\pi(f^{-1}(x))\\left|\\dfrac{df^{-1}}{dx}\\right| = \\pi(f^{-1}(x))|(f^{-1})^{'}(x)|\n",
        "$$\n",
        "\n",
        "В случае многомерной случайной величины выражение схоже\n",
        "\n",
        "$$\n",
        "\\vec{z}\\sim\\pi(\\vec{z}), ~\\vec{x}=f(\\vec{z}),~\\vec{z}=f^{-1}(\\vec{x})\n",
        "$$\n",
        "\n",
        "$$\n",
        "p(\\vec{x}) = \\pi(\\vec{z})\\left|det\\dfrac{d\\vec{z}}{\\vec{x}}\\right| = \\pi(f^{-1}(\\vec{x}))\\left|det\\dfrac{df^{-1}(\\vec{x})}{\\vec{x}}\\right|\n",
        "$$\n",
        "\n",
        "где $det\\frac{df^{-1}(\\vec{x})}{d\\vec{x}}$ — определитель Якобиана функции $f^{-1}$."
      ],
      "metadata": {
        "id": "WX6KRI5WITfh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Теорема об обратных функциях\n",
        "Теорема об обратных функциях говорит о том, что если $y = f(x),~x=f^{-1}(y)$, то\n",
        "$$\n",
        "\\dfrac{df^{-1}(y)}{dy} = \\dfrac{dx}{dy}=\\left(\\dfrac{dy}{dx}\\right)^{-1} = \\left(\\dfrac{df(x)}{dx}\\right)^{-1}\n",
        "$$"
      ],
      "metadata": {
        "id": "3Vw9XephIWC2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Свойство определителя обратной матрицы\n",
        "$$\n",
        "A\\cdot A^{-1} = I \\Rightarrow \\det(A\\cdot A^{-1}) = \\det(I)  \\Rightarrow \\det(A\\cdot A^{-1}) = 1 \\\\\n",
        "\\det(A)\\cdot \\det(A^{-1}) = 1 \\Rightarrow \\det(A^{-1}) = \\dfrac{1}{\\det(A)} = \\det(A)^{-1}\n",
        "$$\n",
        "\n",
        "Таким образом получить из нормально распределенных $z_0$ объекты $x=z_K$ можно через суперпозицию всех функций $f_i$ как\n",
        "$$\n",
        "x=z_K=f_K\\circ f_{K-1}\\circ\\cdots\\circ f_1(z_0)\n",
        "$$\n",
        "\n",
        "Тогда трансформация логарифма плотности распределения\n",
        "$$\n",
        "\\begin{split}\n",
        "\\log p(x) = \\log\\pi_K(z_K) & = \\log\\pi_{K-1}(z_{K-1})-\\log\\left|\\det\\dfrac{df_K}{dz_{K-1}}\\right| \\\\\n",
        "& = \\log\\pi_{K-2}(z_{K-2}) -\\log\\left|\\det\\dfrac{df_{K-1}}{dz_{K-2}}\\right| -\\log\\left|\\det\\dfrac{df_K}{dz_{K-1}}\\right| \\\\\n",
        "& = \\log\\pi_0(z_0) - \\sum\\limits_{i=1}^K\\log\\left|\\det\\dfrac{df_i}{dz_{i-1}}\\right|\n",
        "\\end{split}\n",
        "$$\n",
        "\n",
        "Здесь преобразование $z_i=f_i(z_{i-1})$ называется потоком (flow), а полная последовательность из преобразований $\\pi_i$ называется нормализующим потоком (normalizing flow).\n",
        "\n",
        "Стоит уточнить, что на функции $f_i$ накладывается ряд требований:\n",
        "\n",
        "1. $f_i$ должна быть легко обратимой функцией\n",
        "2. Якобиан $\\frac{df_i}{dz_{i-1}}$ должен быть легко вычислимым"
      ],
      "metadata": {
        "id": "KHeutqrGIXSE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Affine Coupling Layer\n",
        "$$\n",
        "\\begin{cases}\n",
        "y_i = x_i,~\\forall i=1,2,\\dots,d \\\\\n",
        "y_i = x_i \\odot \\exp(s(x_{i-d})) + t(x_{i-d}),~\\forall i=d+1,\\dots,D\n",
        "\\end{cases}\n",
        "$$\n",
        "\n",
        "где $s(\\cdot)$ — масштабирование, $t(\\cdot)$ — смещение, а $\\odot$ — поэлементное умножение.\n",
        "\n",
        "Теперь убедимся, что это преобразование подходит нам по критериям функции $f$."
      ],
      "metadata": {
        "id": "yMbH8flhj9D8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Обратимость\n",
        "$$\n",
        "\\begin{cases}\n",
        "y_i = x_i~,\\\\\n",
        "y_i = x_i \\odot \\exp(s(x_{i-d})) + t(x_{i-d})~;\n",
        "\\end{cases} \\Leftrightarrow\n",
        "\\begin{cases}\n",
        "x_i = y_i~,\\\\\n",
        "x_i = (y_i - t(x_{i-d})) \\odot \\exp(-s(x_{i-d}))~.\n",
        "\\end{cases}\n",
        "$$\n",
        "\n",
        "Так как преобразование линейно, оно не требует поиска обратных функций к $s(\\cdot)$ и $t(\\cdot)$, а значит, что вычисляется быстро."
      ],
      "metadata": {
        "id": "C3M51EAJICr3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Определитель Якобиана\n",
        "\n",
        "Легко заметить, что Якобиан функции имеет вид нижней треугольной матрицы\n",
        "\n",
        "$$\n",
        "J =\n",
        "\\begin{bmatrix}\n",
        "\\mathbf{I} & \\mathbf{0} \\\\\n",
        "\\frac{\\partial y_{d+1:D}}{\\partial x^T_{1:d}} & \\text{diag}(\\exp[s(x_{1:d})])\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "\n",
        "где\n",
        "- $\\mathbf{I}_d$ — единичная матрица, полученная из $\\frac{\\partial y_{1:d}}{\\partial x_{1:d}} = \\frac{\\partial x_{1:d}}{\\partial x_{1:d}}$ размерности $d\\times d$\n",
        "- $\\mathbf{0}$ — нулевая матрица, полученная из $\\frac{\\partial y_{1:d}}{\\partial x_{d+1:D}} = \\frac{\\partial x_{1:d}}{\\partial x_{d+1:D}}$ размерности $d\\times (D-d)$\n",
        "- $\\frac{\\partial y_{d+1:D}}{\\partial x^T_{1:d}}$ — минор Якобиана размерности $(D-d)\\times d$\n",
        "- $\\text{diag}(\\exp[s(x_{1:d})])$ — диагональная матрица, где на диагонали значения $\\exp[s(x_{1:d})]$, а вне — нули. Размерность это матрицы $(D-d)\\times(D-d)$\n",
        "\n",
        "Можно заметить, что такая матрица может существовать только при $d = \\frac{D}{2}$.\n",
        "\n",
        "Так как матрица имеет вид нижней треугольно, ее определитель считается по диагонали, а значит, что левую нижнюю часть матрицы знать не обязательно. Тогда определитель Якобиана вычисляется как\n",
        "\n",
        "$$\n",
        "\\det(J) = \\prod\\limits_{j=1}^{D-d}\\exp(s(x_{1:d}))_j = \\exp\\left(\\sum\\limits_{j=1}^{D-d}s(x_{1:d})_j\\right)\n",
        "$$\n",
        "\n",
        "Так как вычисление определителя сводится к вычислению экспоненты суммы выходов $s(\\cdot)$, считаться определитель будет быстро.\n",
        "\n",
        "Так как к функциям $s(\\cdot)$ и $t(\\cdot)$ не выставлено никаких сложных требований, в их качестве можно использовать функции класса нейронных сетей."
      ],
      "metadata": {
        "id": "jMl8OpSWIFN8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Использование маски\n",
        "\n",
        "Так как маска влияет на порядок строк и столбцов в матрице Якобиана нужно сказать, что перестановка строк или столбцов в определители влияет только на знак определителя матрицы, а так как для вычисления плотности распределения мы используем модуль определителя, перестановка строк и столбцов на вычисление плотности не влияет.\n",
        "\n",
        "Таким образом мы можем свести вычисление оперделителя при использовании маски к базовому определению афинного потока выше, переставляя строки матрицы."
      ],
      "metadata": {
        "id": "ZqIIFQm_IFBs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Деквантизация\n",
        "\n",
        "Нормализующие потоки полагаются на правило изменения переменных, которое естественным образом определено в непрерывном пространстве. Применение потоков непосредственно к дискретным данным приводит к нежелательным моделям плотности, в которых произвольно высокая вероятность присваивается нескольким конкретным значениям.\n",
        "\n",
        "Из-за разницы в свойствах распределений дискретного и непрерывного типов плотность получается неправильной (интеграл не равен единице). С целью исправить это, существует операция деквантизации.\n",
        "\n",
        "<figure>\n",
        "<img src=\"https://github.com/sswt/dive2gai/blob/unit3/unit3/imgs/simple_flow.png\" alt=\"Примеры схем генеративных моделй\" style=\"width:100%\">\n",
        "<figcaption align = \"center\">Пример работы нормализующего потока без квантизации с дискретным распределением.</figcaption>\n",
        "</figure>"
      ],
      "metadata": {
        "id": "WP4Sdc4Nj8-O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Обычная деквантизация\n",
        "\n",
        "Деквантизированную величину обозначим как $v$. тогда операция деквантизации модет быть сформулирована как $v = x + u,~u\\in[0, 1)^D$. Тогда наша плотность описывается как\n",
        "\n",
        "$$\n",
        "p(v) = \\int p(x+u)du = \\int \\dfrac{q(u|x)}{q(x|x)}p(x+u)du = \\mathbb{E}_{u\\sim q(u|x)}\\left[\\dfrac{p(x+u)}{q(u|x)}\\right] = \\mathbb{E}_{u\\sim U(0, 1)^D}[p(x+u)]\n",
        "$$\n",
        "\n",
        "Далее нам нужно применить сигмоидальное преобразование $\\sigma(v)$. Обратное преобразование $\\sigma(v)^{-1}$ имеет вид\n",
        "\n",
        "$$\n",
        "\\sigma(v)^{-1} = \\log z - \\log 1-z\n",
        "$$\n",
        "\n",
        "\n",
        "<figure>\n",
        "<img src=\"https://github.com/sswt/dive2gai/blob/unit3/unit3/imgs/dequant_flow.png\" alt=\"Примеры схем генеративных моделй\" style=\"width:100%\">\n",
        "<figcaption align = \"center\">Пример работы нормализующего потока с простой квантизацией.</figcaption>\n",
        "</figure>"
      ],
      "metadata": {
        "id": "BSQ4CM_zIeOa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Вариационная деквантизация\n",
        "\n",
        "Для деквантизации мы используем нормальное распределение, что может быть некорректно, когда дискретные величины изначально не равновзвешаны. С целью исправить это вводится вариационная деквантизация\n",
        "\n",
        "<figure>\n",
        "<img src=\"https://github.com/sswt/dive2gai/blob/unit3/unit3/imgs/var_deq_flow.png\" alt=\"Примеры схем генеративных моделй\" style=\"width:100%\">\n",
        "<figcaption align = \"center\">Пример работы нормализующего потока с вариационной деквантизацией.</figcaption>\n",
        "</figure>"
      ],
      "metadata": {
        "id": "SIVjD-rPIffP"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kgfWpljBH6iu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yKI7_guJxhPJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gpYK9qORwVz3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "r5wxXlWRwVvA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}