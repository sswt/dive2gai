{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural ODE & SDE models\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Цели:\n",
    "- Познакомиться с Нейронными ОДУ\n",
    "- Познакомиться с Нуйронными СДУ\n",
    "- Узнать, где их можно использовать\n",
    "\n",
    "Содержание:\n",
    "- Neural ODE\n",
    "    - Введение\n",
    "\n",
    "Ссылки:\n",
    "1. [Neural Ordinary Differential Equations](https://arxiv.org/pdf/1806.07366.pdf)\n",
    "2. [Знакомство с Neural ODE](https://habr.com/ru/companies/ods/articles/442002/)\n",
    "3. [Efficient and Accurate Gradients for Neural SDEs](https://arxiv.org/pdf/2105.13493.pdf)\n",
    "\n",
    "Используемые пакеты:\n",
    "1. [Репо torchdiffeq](https://github.com/rtqichen/torchdiffeq/)\n",
    "2. [Репо torchsde](https://github.com/google-research/torchsde/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural ODE\n",
    "\n",
    "### Введение\n",
    "\n",
    "В 2019 году вышла статья **Neural Ordinary Differential Equations** и взяла какие-то (уточнить какие) награды на конференциях. В чем была основная идея и какие проблемы решала данная статья?\n",
    "\n",
    "Рассмотрим простую рекурентную сеть, которая генерирует дискретные временные последовательности\n",
    "$$\n",
    "h_{t+1} = h_t + f(h_t, \\theta_t)\n",
    "$$\n",
    "где $t=0,\\dots,T$ — переменная дискретного времени и $h_t\\in\\mathbb{R}^D$ — состояния модели на $t$-ом шаге.\n",
    "\n",
    "Вопрос: Что будет, если мы увеличим число слоев и уменьшим размер шага по времени? В пределе получим, что данное представление соответствует ОДУ первого порядка\n",
    "$$\n",
    "\\dfrac{dh(t)}{dt} = f(h(t), t, \\theta)\n",
    "$$\n",
    "зная значение функции $h(t)$ в начальный момент времени $h(0)$, мы можем получить его значение $h(T)$ решив задачу Коши\n",
    "$$\n",
    "\\begin{cases}\n",
    "\\dfrac{dh(t)}{dt} = f(h(t), t, \\theta)\\\\\n",
    "h(0) = h_0\n",
    "\\end{cases}\n",
    "$$\n",
    "решить которую мы можем численно. \n",
    "\n",
    "При этом по авторы статьи выделяют следующие плюсы\n",
    "- **Эффективность по памяти:** Авторы предлагают более эфективный способ рассчета обратного распространения ошибки нежели стандартный.\n",
    "\n",
    "- **Адаптивные вычисления:** Варьируя методы решения задачи Коши ОДУ можно балансировать между сложностьи вычислений и невязкой (ошибкой метода).\n",
    "\n",
    "- **Скалируемые и инвертируемые нормализующие потоки:** Авторы показывают, как можно упростить модель NF [рассмотрим в следующей лекции].\n",
    "\n",
    "- **Непрерывные во времени модели временных динамик:** Очевидно, что благодаря подходу можно обучать сети, моделирующие непрерывные динамические системы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Методы решения ОДУ\n",
    "\n",
    "Рассмотрим задачу Коши первого порядка обыкновенного дифференциального уравнения\n",
    "$$\n",
    "\\begin{cases}\n",
    "\\dfrac{dz(t)}{dt} = f(z(t), t) \\\\\n",
    "z(t_0) = z_0\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "Такое уравнение мы можем решать численно методами Рунге-Кутты. Для того чтобы понять, как это работает, рассмотрим вывод самого простого метода — метода Эйлера. Проинтегрируем обе части уравнения\n",
    "$$\n",
    "\\dfrac{dz(t)}{dt} = f(z(t), t)⇒ dz(t) = f(z(t), t)dt⇒\\int dz(t) = \\int f(z(t), t)dt\n",
    "$$\n",
    "Так как численное решение не может быть рассчитано на всем бесконечном временном отрезке, возьмем отрезок $[t_0, t_N]$ для которого определен отрезок $[z_0, z_N]$. Тогда решение на этом отрезке расписывается как определенный интеграл\n",
    "$$\n",
    "\\int\\limits_{z_0}^{z_N} dz(t) = \\int\\limits_{t_0}^{t_N} f(z(t), t)dt⇒z_N - z_0 = \\int\\limits_{t_0}^{t_N} f(z(t), t)dt⇒z_N = z_0 + \\int\\limits_{t_0}^{t_N} f(z(t), t)dt\n",
    "$$\n",
    "Для численного интегрирования воспользуемся методом прямоугольников. Для этого введем равномерную сетку по времени количеством значений $N$ и с шагом $h$ такие, что $h = \\frac{|t_1 - t_0|}{N}↔N=\\frac{|t_1 - t_0|}{h}$. Так сетка по времени выглядит как $t_i=t_0+h\\cdot i,~i=0,\\dots,N$.\n",
    "$$\n",
    "\\int\\limits_{t_0}^{t_N} f(z(t), t)dt≈∑\\limits_{i=0}^N hf(z_i, t_i)⇒z_N = z_0 + ∑\\limits_{i=0}^N hf(z_i, t_i)\n",
    "$$\n",
    "Но так как в задаче Коши нам дано только значение $z(t_0)$, то решать задачу будем итерационно\n",
    "$$\n",
    "z_i = z_{i-1} + hf(z_{i-1}, t_{i-1})\n",
    "$$\n",
    "\n",
    "Оценим его точность. Для этого разложим аналитическое решение в точке $t_i + h$ в ряд Тейлора\n",
    "$$\n",
    "z(t_{i}) = z(t_{i-1} + h) = z(t_{i-1}) + hz'_t(t_{i-1})+O(h^2) = z(t_{i-1}) + hf(z_{i-1}, t_{i-1})+O(h^2)\n",
    "$$\n",
    "И вычтем решение методом Эйлера из аналитического решения\n",
    "$$\n",
    "\\Delta = z(t_{i-1}) + hf(z_{i-1}, t_{i-1}) + O(h^2) - z_{i-1} + hf(z_{i-1}, t_{i-1}) = O(h^2)\n",
    "$$\n",
    "Получили ошибку на одном шаге. Очевидно, что для получения ошибки на всем интервале, нужно проитегрировать "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
