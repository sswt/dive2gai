{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b1qxI8XjJbFs"
      },
      "source": [
        "# Вариационная нижняя граница\n",
        "\n",
        "Цели:\n",
        "\n",
        "* Вспомнить, что такое KL-дивергенция и как она выводится\n",
        "* Получить представление о том, как используется ELBO в VAE\n",
        "\n",
        "Содержание:\n",
        "\n",
        "* [KL-дивергенция](#kld)\n",
        "  * Вывод формулы\n",
        "  * Прямая и обратная KL-дивергенция\n",
        "* [Формула Байеса](#bayes)\n",
        "* [ELBO](#elbo)\n",
        "* [Обучение VAE](#vae)\n",
        "  * Трюк репараметризации\n",
        "  * Реализация\n",
        "\n",
        "\n",
        "Ссылки:\n",
        "\n",
        "* [VAE](https://www.youtube.com/watch?v=9_eZHt2qJs4) and [ELBO](https://www.youtube.com/watch?v=IXsA5Rpp25w) clearly explained\n",
        "* [\"From Autoencoder to Beta-VAE\" страничка в блоге Lilian Weng](https://lilianweng.github.io/posts/2018-08-12-vae/)\n",
        "* [Variational inference & deep learning. A new synthesis, Kingma, D.P. PhD Thesis](https://pure.uva.nl/ws/files/17891313/Thesis.pdf) - от автора публикации про VAE\n",
        "* [Дмитрий Кропотов | Вариационный авто-кодировщик. Летняя школа AIRI 2022](https://www.youtube.com/watch?v=wRHUc44PJuE)\n",
        "* Дмитрий Ветров. Летняя школа AIRI 2022. Состоит из двух частей:\n",
        "  * [Введение в байесовский подход к теории вероятностей. Основы байесовского вывода.](https://www.youtube.com/watch?v=RZGdMiBOYwk)\n",
        "  * [Вариационный вывод. Дважды-стохастический вывод. Вариационный авто-кодировщик.](https://www.youtube.com/watch?v=QEBKaM3z1sM)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Co5FJ2ZvLpSp"
      },
      "source": [
        "<a name=\"kld\"></a>\n",
        "## KL-дивергенция\n",
        "\n",
        "KL-дивергенция получила своё название по имени двух учёных - Solomon **K**ullback и Richard **L**eibler, она также называется дивергенция Кульбака-Лейблера.\n",
        "\n",
        "Она нужна для того, чтобы измерить, насколько одно распределение вероятности, отличается от другого, базового. Часто используется, когда мы хотим аппроксимировать какое-то сложное распределение более простым."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zk1aRk4Piq1U"
      },
      "source": [
        "Пусть $X = \\{x_1, x_2, ..., x_n\\}$ - случайная величина (СВ).\n",
        "\n",
        "Обозначим $p_\\theta$ и $q_ϕ$ - наши распределения, которые мы хотим сравнить, где $\\theta$ и $\\phi$ - параметры распределения.\n",
        "\n",
        "Тогда $p_\\theta(x_i)$ и $q_ϕ(x_i)$ - вероятности конкретных значений.\n",
        "\n",
        "Вероятности могут быть очень малыми числами, поэтому часто работают с логарифмами вероятностей."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aB1fQsJLjSBk",
        "outputId": "2a10e062-9146-485a-e41d-75c847e308c5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.000001 -> -13.815511\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# let's check for some small value\n",
        "p = 1e-6\n",
        "print(f'{p:.6f} -> {np.log(p):.6f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iYAdF3aJKuyB"
      },
      "source": [
        "### Вывод формулы"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oxuvzYKAU8uH"
      },
      "source": [
        "Если мы хотим измерить отличие распределений, то можно просто посчитать разницу\n",
        "\n",
        "$log\\ p_\\theta(x_i) - log\\ q_ϕ(x_i) = log\\Big[\\frac{p_\\theta(x_i)}{q_ϕ(x_i)}\\Big]$\n",
        "\n",
        "Выражение под скобками называется коэффициент правдоподобия (**likelihood ratio**).\n",
        "\n",
        "Но это разница между какими-то конкретными значениями, а у нас распределения, поэтому мы хотим знать мат. ожидание разницы.\n",
        "\n",
        "Мат. ожидание дискретной СВ считается как:\n",
        "\n",
        "$\\mathbb{E_{p_\\theta}}[X] = \\displaystyle\\sum_{i=1}^{\\infty}x_ip_\\theta(x_i)$\n",
        "\n",
        "Также можно посчитать мат. ожидание значения функции от дискретной СВ (оно нам позже пригодится):\n",
        "\n",
        "$\\mathbb{E_{p_\\theta}}[h(X)] = \\displaystyle\\sum_{i=1}^{\\infty}h(x_i)p_\\theta(x_i)$\n",
        "\n",
        "Для непрерывной СВ:\n",
        "\n",
        "$\\mathbb{E_{p_\\theta}}[h(X)] = \\displaystyle\\int{h(x)p_\\theta(x)\\ \\mathrm{d}x}$\n",
        "\n",
        "Логарифм коэффициента правдоподобия не что иное, как функция от СВ, поэтому чтобы получить его мат. ожидание, достаточно посчитать:\n",
        "\n",
        "$\\mathbb{E}\\Big[log\\frac{p_\\theta(x)}{q_ϕ(x)}\\Big] = \\displaystyle\\sum_{i=1}^{\\infty}p_\\theta(x_i)log\\Big[\\frac{p_\\theta(x_i)}{q_ϕ(x_i)}\\Big]$\n",
        "\n",
        "Для непрерывной СВ соответственно:\n",
        "\n",
        "$\\mathbb{E}\\Big[log\\frac{p_\\theta(x)}{q_ϕ(x)}\\Big] = \\displaystyle\\int{p_\\theta(x)log\\Big[\\frac{p_\\theta(x)}{q_ϕ(x)}\\Big]\\ \\mathrm{d}x}$\n",
        "\n",
        "Это и есть KL-дивергенция:\n",
        "\n",
        "$D_{KL}(p_\\theta \\parallel q_ϕ)= \\displaystyle\\int{p_\\theta(x)log\\Big[\\frac{p_\\theta(x)}{q_ϕ(x)}\\Big]\\ \\mathrm{d}x}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7LH8VHjhWeTN"
      },
      "source": [
        "Но у нас сумммирование по бесконечному набору значений и интеграл по всей действительной оси, как это вычислить на практике?\n",
        "\n",
        "Закон больших чисел говорит, что среднее СВ при большом количестве наблюдений стремится к мат. ожиданию.\n",
        "\n",
        "Перепишем формулу (теперь она одинаковая для дискретных и непрерывных СВ):\n",
        "\n",
        "$\\mathbb{E}\\Big[log\\frac{p_\\theta(x)}{q_ϕ(x)}\\Big] \\approx \\frac1N\\displaystyle\\sum_{i=1}^Np_\\theta(x_i)log\\Big[\\frac{p_\\theta(x_i)}{q_ϕ(x_i)}\\Big]$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ldSLiyQN60G"
      },
      "source": [
        "### Прямая и обратная KL-дивергенция"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BgK4ka03WgaC"
      },
      "source": [
        "KL-дивергенция несимметрична и для $q_\\phi$ она будет считаться так:\n",
        "\n",
        "$D_{KL}(q_ϕ \\parallel p_\\theta)= \\displaystyle\\int{q_\\phi(x)log\\Big[\\frac{q_ϕ(x)}{p_\\theta(x)}\\Big]\\ \\mathrm{d}x}$\n",
        "\n",
        "Значение очевидно будет другим для тех же $p_\\theta$ и $q_\\phi$, поэтому она не является метрикой:\n",
        "\n",
        "$D_{KL}(p_\\theta \\parallel q_ϕ) \\ne D_{KL}(q_ϕ \\parallel p_\\theta)$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8KWLutJvLXew"
      },
      "source": [
        "Кстати левая часть называется Forward KL, правая - Reverse KL.\n",
        "\n",
        "Интересно посмотреть на разницу между ними, когда мы пытаемся аппроксимировать бимодальное базовое распределение унимодальным:\n",
        "\n",
        "* дивергенция меньше, если приближение лучше в точках, где базовое распределение имее большие значения, поэтому при обратной $Q$ соответствует моде распределения $P$\n",
        "* при прямой $Q$ стремится покрыть базовое распределение $P$ целиком\n",
        "\n",
        "<figure>\n",
        "<img src=\"https://lilianweng.github.io/posts/2018-08-12-vae/forward_vs_reversed_KL.png\" alt=\"Forward vs Reverse KL\" style=\"width:100%\">\n",
        "<figcaption align = \"center\"> Image credit: <a href=\"https://blog.evjang.com/2016/08/variational-bayes.html\">Eric Jang's blog</a></figcaption>\n",
        "</figure>\n",
        "\n",
        "\n",
        "Нас интересует скорее мода, это соответствует максимуму апостериорного распределения.\n",
        "\n",
        "При оценке плотности распределения и в вариационном выводе используется именно Reverse KL, а Forward KL неявно используется в ML, в частности когда функция потерь - кросс-энтропия."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FdtgCQIaOrVb"
      },
      "source": [
        "<a name=\"bayes\"></a>\n",
        "## Формула Байеса\n",
        "\n",
        "$\\text{posterior} = \\frac{\\text{likelihood}\\ \\times \\text{prior}}{\\text{evidence}}$\n",
        "\n",
        "Формула Байеса для получения апостериорного распределения латентной переменной $z$:\n",
        "\n",
        "$p_\\theta(z | x) = \\frac{p_\\theta(x | z)p_\\theta(z)}{p_\\theta(x)}$, где\n",
        "\n",
        "* $p_\\theta(z | x)$ - апостериорное распределение после того, как мы пронаблюдали (posterior) $x$\n",
        "* $p_\\theta(x | z)$ - правдоподобие данных при условии $z$ (likelihood)\n",
        "* $p_\\theta(z)$ - априорное распределение до того, как мы пронаблюдали $x$ (prior)\n",
        "* $p_\\theta(x)$ - нормировочная константа или обоснованность (evidence)\n",
        "\n",
        "В знаменателе\n",
        "\n",
        "$p_\\theta(x) = \\displaystyle\\int{p_\\theta(x | z)p_\\theta(z)\\ \\mathrm{d}x}$\n",
        "\n",
        "находится неберущийся для многомерных пространств интеграл.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t2wZgUqqLxoj"
      },
      "source": [
        "<a name=\"elbo\"></a>\n",
        "## ELBO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l3wFa5l5LQF8"
      },
      "source": [
        "Итак у нас есть какое-то сложное распределение $p(x|\\theta)$ (запись $p_\\theta(x)$ эквивалентна) и мы хотим максимизировать логарифм правдоподобия $log\\ p_θ(x)$ по параметрам θ.\n",
        "\n",
        "Вводим латентную переменную $z$, тогда\n",
        "\n",
        "$log\\ p_θ(x) = \\displaystyle\\int{log\\ p_θ(x, z)\\mathrm{d}z} = \\displaystyle\\int{log\\ p_θ(z | x)p_θ(x)\\ \\mathrm{d}z}$\n",
        "\n",
        "Интеграл этот неберущийся в большинстве случаев, а сложность численного интегрирования растёт экспоненциально с увеличением размерности пространства."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hdLCeqTMsJ0i"
      },
      "source": [
        "Какой выход - использовать вариационный вывод, который предлагает нам для вычисления апостериорного распределения $p_\\theta(z | x)$ использовать аппроксимацию более простым расеределением $q_\\phi(z | x)$, для которого мы знаем как делать апостериорный вывод и из которого будет легко сэмплировать. И подберём параметры $\\phi$ так, чтобы оно было близко к истинному.\n",
        "\n",
        "NOTE: В вариационном исчислении мы ищем функцию, при которой функционал достигает максимального значения. Функционал - это функция от функций. А мы ищем в семействе распределений то, которое даёт нам максимум правдоподобия.\n",
        "\n",
        "Будем подбирать параметры $\\phi$ путём оптимизации функции потерь. В качестве меры непохожести между истинным распределением и аппроксимацией будем использовать KL-дивергенцию.\n",
        "\n",
        "Задача превращается в задачу минимизации обратной KL-дивергенции между p и q (мат. ожидание коэффициента правдоподобия):\n",
        "\n",
        "$D_{KL}(q_ϕ∥p_θ) = \\mathbb{E}_{q_\\phi}\\Big[log\\frac{q_ϕ(z|x)}{p_\\theta(z|x)}\\Big]$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EY7fqbNvMuE0"
      },
      "source": [
        "Но как вычислить знаменатель?\n",
        "\n",
        "Разделим проблему на части:\n",
        "\n",
        "$\\mathbb{E}_{q_\\phi}\\Big[log\\frac{q_ϕ(z|x)}{p_\\theta(z|x)}\\Big] = \\mathbb{E}_{q_\\phi}[log\\ {q_ϕ(z|x)}] - \\mathbb{E}_{q_\\phi}[log\\ p_\\theta(z|x)]$\n",
        "\n",
        "Распишем второй член по формуле условной вероятности:\n",
        "\n",
        "$ = \\mathbb{E}_{q_\\phi}[log\\ {q_ϕ(z|x)}] - \\mathbb{E}_{q_\\phi}\\Big[log\\frac{p_θ(z,x)}{p_θ(x)}\\Big]$\n",
        "\n",
        "Воспользуемся свойствами логарифма:\n",
        "\n",
        "$ = \\mathbb{E}_{q_\\phi}[log\\ {q_ϕ(z|x)}] - \\mathbb{E}_{q_\\phi}[log\\ p_θ(z,x)] + \\mathbb{E}_{q_\\phi}[log\\ p_θ(x)]$\n",
        "\n",
        "Распишем мат. ожидание в третьем члене:\n",
        "\n",
        "$ = \\mathbb{E}_{q_\\phi}[log\\ {q_ϕ(z|x)}] - \\mathbb{E}_{q_\\phi}[log\\ p_θ(z,x)] + \\displaystyle\\int{q_ϕ(z|x)log\\ p_θ(x)\\mathrm{d}z}$\n",
        "\n",
        "Вынесем константу за интеграл:\n",
        "\n",
        "$ = \\mathbb{E}_{q_\\phi}[log\\ {q_ϕ(z|x)}] - \\mathbb{E}_{q_\\phi}[log\\ p_θ(z,x)] + log\\ p_θ(x)\\displaystyle\\int{q_ϕ(z|x)\\mathrm{d}z}$\n",
        "\n",
        "Так как интеграл функции плотности вероятности равен 1, получим:\n",
        "\n",
        "$ = \\mathbb{E}_{q_\\phi}[log\\ {q_ϕ(z|x)}] - \\mathbb{E}_{q_\\phi}[log\\ p_θ(z,x)] + log\\ p_θ(x)$\n",
        "\n",
        "Третий компонент - логарифм маргинального правдоподобия (marginal log likelihood) или логарифм \"обоснованности\" (evidence). Маргинальная - в том смысле, что мы уже проинтегрировали по скрытой переменой $z$. Ещё его называют логарифм неполного правдоподобия.\n",
        "\n",
        "Переносим логарифм правдоподобия влево:\n",
        "\n",
        "$log\\ p_θ(x) = - \\mathbb{E}_{q_\\phi}[log\\ {q_ϕ(z|x)}] + \\mathbb{E}_{q_\\phi}[log\\ p_θ(z,x)] + D_{KL}(q_ϕ∥p_θ) \\quad\\quad(1)$\n",
        "\n",
        "При этом KL-дивергенция неотрицательная:\n",
        "\n",
        "$D_{KL}(q_ϕ∥p_θ) ≥ 0$\n",
        "\n",
        "Отсюда получаем, что\n",
        "\n",
        "$log\\ p_θ(x) ≥ - \\mathbb{E}_{q_\\phi}[log\\ {q_ϕ(z|x)}] + \\mathbb{E}_{q_\\phi}[log\\ p_θ(z,x)]$\n",
        "\n",
        "Правая часть выражения называется вариационной нижней границей (Variational Lower Bound или Evidence Lower BOund).\n",
        "\n",
        "Правая часть в формуле (1) не зависит от $z$, поэтому если мы максимизируем ELBO, мы неявно минимизируем KL-дивергенцию в формуле.\n",
        "\n",
        "Упростим ещё:\n",
        "\n",
        "$ELBO = - \\mathbb{E}_{q_\\phi}[log\\ {q_ϕ(z|x)}] + \\mathbb{E}_{q_\\phi}[log\\ p_θ(z,x)]$\n",
        "\n",
        "$= - \\mathbb{E}_{q_\\phi}[log\\ {q_ϕ(z|x)}] + \\mathbb{E}_{q_\\phi}[log\\ p_θ(x|z)]  + \\mathbb{E}_{q_\\phi}[log\\ p_θ(z)]$\n",
        "\n",
        "$= \\mathbb{E}_{q_\\phi}[log\\ p_θ(x|z)] - \\mathbb{E}_{q_\\phi}[log\\ {q_ϕ(z|x)}] + \\mathbb{E}_{q_\\phi}[log\\ p_θ(z)]$\n",
        "\n",
        "$= \\mathbb{E}_{q_\\phi}[log\\ p_θ(x|z)] - \\mathbb{E}_{q_\\phi}\\Big[log\\frac{{q_ϕ(z|x)}}{p_θ(z)}\\Big]$\n",
        "\n",
        "Первый член выражения говорит, что это мат. ожидание ошибки аппроксимации (expected reconstruction error), а вторая - KL-дивергенция между аппроксимированным апостериорным распределением и априорным распределением.\n",
        "\n",
        "Будем использовать $-ELBO$ в качестве функции потерь."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mgUI9U2owVoz"
      },
      "source": [
        "<a name=\"vae\"></a>\n",
        "## Обучение VAE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Qwr6M0yeN2S"
      },
      "source": [
        "VAE состоит из двух частей:\n",
        "\n",
        "* энкодер, который отображает сложное входное распределение в многомерное нормальное - аппроксимирует распределение $q_ϕ(z|x)$ по параметрам $ϕ$\n",
        "* декодер, отображающий нормальное распределение обратно в исходное - аппроксимирует $p_θ(x|z)$ по параметрам $θ$\n",
        "\n",
        "Задача - найти минимум целевой функции $\\underset{θ, ϕ}{\\mathrm{argmin}} \\ \\mathcal L = \\underset{θ, ϕ}{\\mathrm{argmin}} -\\mathbb{E}_{q_\\phi}[log\\ p_θ(x|z)] + \\mathbb{E}_{q_\\phi}\\Big[log\\frac{{q_ϕ(z|x)}}{p_θ(z)}\\Big]$.\n",
        "\n",
        "Первый член с мат. ожиданием в выражении выше требует сэмплирования из многомерного нормального распределения. Сэмплирование является стохастическим процессом и через него не будут распространяться обратно градиенты."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yM5cXSxBjYhi"
      },
      "source": [
        "### Трюк репараметризации\n",
        "\n",
        "Репараметризуемое распределение - то, которое можно выразить как детерминированную функцию от непараметрического распределения.\n",
        "\n",
        "$z ∼ q_ϕ(z|x) = \\mathcal N(z; μ, diag(σ^2))$\n",
        "\n",
        "$z = μ + σ \\odot ϵ, где \\ ϵ \\sim \\mathcal N(0, I), \\odot - поэлементное \\ произведение$\n",
        "\n",
        "<figure>\n",
        "<img src=\"https://lilianweng.github.io/posts/2018-08-12-vae/reparameterization-trick.png\" alt=\"Reparametrisation trick\" style=\"width:100%\">\n",
        "<figcaption align = \"center\"> Image credit: <a href=\"https://lilianweng.github.io/posts/2018-08-12-vae/\">Lilian Weng's blog</a></figcaption>\n",
        "</figure>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PRRqQlNM8btS"
      },
      "source": [
        "### Реализация\n",
        "\n",
        "На практике функцию потерь вычисляют как сумму BCE\n",
        "\n",
        "$BCE(y,\\hat y)=−y\\cdot log(\\hat y)−(1−y)\\cdot log(1−\\hat y)$\n",
        "\n",
        "и KL-дивергенции распределения $q_ϕ(z|x)$ со стандартным нормальным, которая выступает в роли регуляризатора.\n",
        "\n",
        "При сравнении нормального распределения со стандартным она расписывается следующим образом:\n",
        "\n",
        "$D_{KL}(\\mathcal{N}(\\mu,\\upsilon)\\parallel \\mathcal{N}(0,1))=\\frac{1}{2}\\displaystyle\\sum_{i=1}^d\\upsilon_i - log(\\upsilon_i) - 1 + \\mu_i^2$\n",
        "\n",
        "Оптимизируется стохастическим градиентным спуском."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UfA76uy98qe-"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
